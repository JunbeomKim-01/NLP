# 정제 및 정규화
## 텍스트 데이터를 용도에 맞게 정제 및 정규화 작업이 필요합니다.

### 정제:갖고 있는 코퍼스로부터 노이즈 데이터를 제거한다.
### 정규화:표현방법이 다른 단어들을 통합시켜 같은 단어로 만들어준다.

# 정규화 기법
## 1.규칙에 기반한 표기가 다른 단어들 통합
#### 표기가 다른 단어를 하나의 단어로 정규화 하는 방법이 있습니다.
#### USA와 US는 같은 의미를 가지므로, 하나의 단어로 정규화해볼 수 있습니다.
#### uh-huh와 uhhuh는 형태는 다르지만 여전히 같은 의미를 갖고 있습니다. 이러한 정규화를 거치게 되면, US를 찾아도 USA도 함께 찾을 수 있을 것입니다.

## 2.대,소문자 통합
#### 영어권 언어에서 대, 소문자를 통합하는 것은 단어의 개수를 줄일 수 있는 또 다른 정규화 방법입니다.
#### 소문자 변환이 왜 유용한지 예를 들어보도록 하겠습니다. 가령, Automobile이라는 단어가 문장의 첫 단어였기때문에 A가 대문자였다고 생각해봅시다. 여기에 소문자 변환을 사용하면, automobile을 찾는 질의(query)에서, 결과로서 Automobile도 찾을 수 있게 됩니다.
## 3.불필요한 단어의 제거
### 노이즈 데이터= 특수문자,의미를 갖지 않는 단어,분석하는 목적과 맞지 않는 단
### (1)등장 빈도가 적은 단어
#### 단어가 너무 적게 등장해서 자연어 처리에 도움을 주지 않는 단어들이 존재할 수 있음
#### Ex) 1만개의 스팸 메일 중 단 5번만 출현된 단어는 직관적으로 분류에 도움이 거의 되지 않는다.
### (2) 길이가 짧은 단
#### 영어권 언어에서는 길이가 짧은 단어를 삭제하는 것만으로도 어느정도 자연어 처리에서 크게 의미가 없는 단어들을 제거하는 효과를 볼 수 있다고 알려져 있습니다.
#### 영어권에서는 짧은 단어가 불용어일 가능성이 높습니다. 단어의 길이가 1인 관형어 a 나 주어 I를 제거할 수 있으면 2글자인  it, at, to, on, in, by 등과 같은 대부분 불용어에 해당되는 단어들이 제거됩니다.그렇지만 단어의 길이가 짧은 것 중에는 중요한 단어도 있으니 사용하기 전 고민이 필요합니다.

## 4.정규 표현식
#### 얻어낸 코퍼스에서 노이즈 데이터의 특징을 잡아낼 수 있다면, 정규 표현식을 통해서 이를 제거할 수 있는 경우가 많습니다. 가령, HTML 문서로부터 가져온 코퍼스라면 문서 여기저기에 HTML 태그가 있습니다. 뉴스 기사를 크롤링 했다면, 기사마다 게재 시간이 적혀져 있을 수 있습니다. 정규 표현식은 이러한 코퍼스 내에 계속해서 등장하는 글자들을 규칙에 기반하여 한 번에 제거하는 방식으로서 매우 유용합니다.

## 길이가 1~2인 단어들을 정규 표현식을 이용하여 제거하기
```python
import re
text = "I was wondering if anyone out there could enlighten me on this car."
shortword = re.compile(r'\W*\b\w{1,2}\b')
print('')
print(shortword.sub('', text))
```